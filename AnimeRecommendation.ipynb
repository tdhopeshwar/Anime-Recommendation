{
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 6207733,
          "sourceType": "datasetVersion",
          "datasetId": 3384322
        },
        {
          "sourceId": 148576,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": true,
          "modelInstanceId": 126078,
          "modelId": 149056
        }
      ],
      "dockerImageVersionId": 30787,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries\n"
      ],
      "metadata": {
        "id": "qAAsYnBSorCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas\n",
        "!pip install scikit-learn\n"
      ],
      "metadata": {
        "id": "Ve6YHXqInDQw",
        "outputId": "0a77ecb3-4314-4e5b-dfa0-df40dc3292bb",
        "execution": {
          "iopub.status.busy": "2024-10-28T08:26:55.280808Z",
          "iopub.execute_input": "2024-10-28T08:26:55.281760Z",
          "iopub.status.idle": "2024-10-28T08:27:19.979378Z",
          "shell.execute_reply.started": "2024-10-28T08:26:55.281707Z",
          "shell.execute_reply": "2024-10-28T08:27:19.978166Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\nRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "qPzPwyc-nDQ0",
        "execution": {
          "iopub.status.busy": "2024-10-28T08:27:19.982233Z",
          "iopub.execute_input": "2024-10-28T08:27:19.982927Z",
          "iopub.status.idle": "2024-10-28T08:27:24.785608Z",
          "shell.execute_reply.started": "2024-10-28T08:27:19.982878Z",
          "shell.execute_reply": "2024-10-28T08:27:24.784696Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Device Configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "if device.type == \"cuda\":\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
      ],
      "metadata": {
        "id": "PiQ5crwBnDQ1",
        "outputId": "286570b3-054b-4afe-f699-5698c89c9303",
        "execution": {
          "iopub.status.busy": "2024-10-28T08:27:24.787006Z",
          "iopub.execute_input": "2024-10-28T08:27:24.787568Z",
          "iopub.status.idle": "2024-10-28T08:27:24.877360Z",
          "shell.execute_reply.started": "2024-10-28T08:27:24.787522Z",
          "shell.execute_reply": "2024-10-28T08:27:24.876372Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Using device: cuda\nGPU Name: Tesla T4\nGPU Memory: 15.83 GB\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Data"
      ],
      "metadata": {
        "id": "O9xUvFmao67Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Data Loading\n",
        "anime_df = pd.read_csv('/kaggle/input/myanimelist-dataset/anime-dataset-2023.csv')\n",
        "users_df = pd.read_csv('/kaggle/input/myanimelist-dataset/users-details-2023.csv')\n",
        "scores_df = pd.read_csv('/kaggle/input/myanimelist-dataset/users-score-2023.csv')"
      ],
      "metadata": {
        "id": "k5QPfK0unDQ2",
        "execution": {
          "iopub.status.busy": "2024-10-28T08:27:24.878518Z",
          "iopub.execute_input": "2024-10-28T08:27:24.878848Z",
          "iopub.status.idle": "2024-10-28T08:27:59.889551Z",
          "shell.execute_reply.started": "2024-10-28T08:27:24.878815Z",
          "shell.execute_reply": "2024-10-28T08:27:59.888455Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preprocessing\n"
      ],
      "metadata": {
        "id": "5skU4zQ1pAfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Drop unnecessary columns from users_df\n",
        "users_df = users_df.drop(columns=['Gender', 'Location'])"
      ],
      "metadata": {
        "id": "9t9lnhqhnDQ3",
        "execution": {
          "iopub.status.busy": "2024-10-28T08:27:59.892615Z",
          "iopub.execute_input": "2024-10-28T08:27:59.893443Z",
          "iopub.status.idle": "2024-10-28T08:27:59.952689Z",
          "shell.execute_reply.started": "2024-10-28T08:27:59.893395Z",
          "shell.execute_reply": "2024-10-28T08:27:59.951729Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Handle Missing Ranks\n",
        "anime_df['Rank'] = pd.to_numeric(anime_df['Rank'], errors='coerce')\n",
        "known_ranks = anime_df[anime_df['Rank'].notna()]\n",
        "missing_ranks = anime_df[anime_df['Rank'].isna()]\n",
        "\n",
        "# Train linear regression for rank prediction\n",
        "X_train = known_ranks[['Popularity']]\n",
        "y_train = known_ranks['Rank']\n",
        "regressor = LinearRegression()\n",
        "regressor.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "S94-ivDInDQ4",
        "outputId": "07655ec1-2a1b-44ed-c7b2-b2bc952eacfe",
        "execution": {
          "iopub.status.busy": "2024-10-28T08:27:59.954045Z",
          "iopub.execute_input": "2024-10-28T08:27:59.954803Z",
          "iopub.status.idle": "2024-10-28T08:28:00.010845Z",
          "shell.execute_reply.started": "2024-10-28T08:27:59.954757Z",
          "shell.execute_reply": "2024-10-28T08:28:00.009972Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "LinearRegression()",
            "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict missing ranks\n",
        "X_missing = missing_ranks[['Popularity']]\n",
        "predicted_ranks = regressor.predict(X_missing)\n",
        "anime_df.loc[anime_df['Rank'].isna(), 'Rank'] = predicted_ranks"
      ],
      "metadata": {
        "id": "Vbm3L-dtnDQ5",
        "execution": {
          "iopub.status.busy": "2024-10-28T08:28:00.011929Z",
          "iopub.execute_input": "2024-10-28T08:28:00.012245Z",
          "iopub.status.idle": "2024-10-28T08:28:00.019883Z",
          "shell.execute_reply.started": "2024-10-28T08:28:00.012212Z",
          "shell.execute_reply": "2024-10-28T08:28:00.018898Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merging Data frames\n"
      ],
      "metadata": {
        "id": "NaiFMs7Spori"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Merge DataFrames\n",
        "users_df.rename(columns={'Mal ID': 'user_id'}, inplace=True)\n",
        "merged_df = scores_df.merge(users_df, on='user_id').merge(anime_df, on='anime_id')\n"
      ],
      "metadata": {
        "id": "QSP95bu8nDQ5",
        "execution": {
          "iopub.status.busy": "2024-10-28T08:28:00.021140Z",
          "iopub.execute_input": "2024-10-28T08:28:00.021832Z",
          "iopub.status.idle": "2024-10-28T08:28:46.738524Z",
          "shell.execute_reply.started": "2024-10-28T08:28:00.021790Z",
          "shell.execute_reply": "2024-10-28T08:28:46.737694Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_drop = [\n",
        "    'Birthday', 'Favorites', 'Premiered', 'Other name', 'Username_y',\n",
        "    'Synopsis', 'Image URL', 'Licensors', 'Producers', 'Aired',\n",
        "    'Members', 'Scored By', 'Duration', 'Studios', 'Status',\n",
        "    'Episodes', 'Anime Title', 'English name', 'Username_x',\n",
        "    'Name', 'Score'  # Additional columns to drop\n",
        "]\n"
      ],
      "metadata": {
        "id": "WDskEjoxnDQ5",
        "execution": {
          "iopub.status.busy": "2024-10-28T08:28:46.739733Z",
          "iopub.execute_input": "2024-10-28T08:28:46.740057Z",
          "iopub.status.idle": "2024-10-28T08:28:46.745197Z",
          "shell.execute_reply.started": "2024-10-28T08:28:46.740023Z",
          "shell.execute_reply": "2024-10-28T08:28:46.744284Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = merged_df.drop(columns=columns_to_drop)\n"
      ],
      "metadata": {
        "id": "XJeecW-6nDQ6",
        "execution": {
          "iopub.status.busy": "2024-10-28T08:28:46.746503Z",
          "iopub.execute_input": "2024-10-28T08:28:46.746874Z",
          "iopub.status.idle": "2024-10-28T08:28:50.738099Z",
          "shell.execute_reply.started": "2024-10-28T08:28:46.746830Z",
          "shell.execute_reply": "2024-10-28T08:28:50.737285Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Reduce Dataset Size (optional)\n",
        "merged_df = merged_df.sample(frac=0.5, random_state=42).reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "YNi1ZmrCnDQ7",
        "execution": {
          "iopub.status.busy": "2024-10-28T08:28:50.739228Z",
          "iopub.execute_input": "2024-10-28T08:28:50.739551Z",
          "iopub.status.idle": "2024-10-28T08:29:06.207681Z",
          "shell.execute_reply.started": "2024-10-28T08:28:50.739507Z",
          "shell.execute_reply": "2024-10-28T08:29:06.206870Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = merged_df.drop(columns=['Joined'])"
      ],
      "metadata": {
        "id": "YdcZawG6nDQ7",
        "execution": {
          "iopub.status.busy": "2024-10-28T08:29:06.208872Z",
          "iopub.execute_input": "2024-10-28T08:29:06.209212Z",
          "iopub.status.idle": "2024-10-28T08:29:07.320877Z",
          "shell.execute_reply.started": "2024-10-28T08:29:06.209178Z",
          "shell.execute_reply": "2024-10-28T08:29:07.319996Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.head().T"
      ],
      "metadata": {
        "id": "mP2Ty_o-nDQ8",
        "outputId": "a4a12417-d30c-40d0-c561-d55b24b5989c",
        "execution": {
          "iopub.status.busy": "2024-10-28T08:29:07.322020Z",
          "iopub.execute_input": "2024-10-28T08:29:07.322328Z",
          "iopub.status.idle": "2024-10-28T08:29:07.341624Z",
          "shell.execute_reply.started": "2024-10-28T08:29:07.322296Z",
          "shell.execute_reply": "2024-10-28T08:29:07.340797Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                          0  \\\nuser_id                             1233963   \nanime_id                              23277   \nrating                                    7   \nDays Watched                           86.9   \nMean Score                             7.87   \nWatching                                9.0   \nCompleted                             470.0   \nOn Hold                                68.0   \nDropped                                40.0   \nPlan to Watch                          12.0   \nTotal Entries                         599.0   \nRewatched                               2.0   \nEpisodes Watched                     5883.0   \nGenres               Comedy, Romance, Ecchi   \nType                                     TV   \nSource                          Light novel   \nRating            PG-13 - Teens 13 or older   \nRank                                 1770.0   \nPopularity                              301   \n\n                                                       1  \\\nuser_id                                           301489   \nanime_id                                           12445   \nrating                                                 7   \nDays Watched                                       101.9   \nMean Score                                           7.3   \nWatching                                             5.0   \nCompleted                                          252.0   \nOn Hold                                             13.0   \nDropped                                             15.0   \nPlan to Watch                                       80.0   \nTotal Entries                                      365.0   \nRewatched                                            3.0   \nEpisodes Watched                                  6255.0   \nGenres            Horror, Mystery, Romance, Supernatural   \nType                                                  TV   \nSource                                             Manga   \nRating                    R - 17+ (violence & profanity)   \nRank                                               870.0   \nPopularity                                           542   \n\n                                                    2  \\\nuser_id                                        325075   \nanime_id                                          451   \nrating                                              5   \nDays Watched                                     67.4   \nMean Score                                       8.02   \nWatching                                          2.0   \nCompleted                                        63.0   \nOn Hold                                           1.0   \nDropped                                           1.0   \nPlan to Watch                                    13.0   \nTotal Entries                                    80.0   \nRewatched                                        39.0   \nEpisodes Watched                               3940.0   \nGenres            Action, Adventure, Fantasy, Romance   \nType                                            Movie   \nSource                                          Manga   \nRating                      PG-13 - Teens 13 or older   \nRank                                            918.0   \nPopularity                                       1955   \n\n                                                  3                          4  \nuser_id                                     1166847                    1104637  \nanime_id                                        572                       7593  \nrating                                            9                          9  \nDays Watched                                   26.3                       71.3  \nMean Score                                     8.51                       7.88  \nWatching                                        4.0                        4.0  \nCompleted                                      91.0                      130.0  \nOn Hold                                        11.0                        0.0  \nDropped                                        10.0                        0.0  \nPlan to Watch                                  13.0                       18.0  \nTotal Entries                                 129.0                      152.0  \nRewatched                                       1.0                        0.0  \nEpisodes Watched                             1981.0                     4301.0  \nGenres            Adventure, Award Winning, Fantasy     Comedy, Romance, Ecchi  \nType                                          Movie                         TV  \nSource                                        Manga                      Manga  \nRating                    PG-13 - Teens 13 or older  PG-13 - Teens 13 or older  \nRank                                          197.0                     5761.0  \nPopularity                                      611                        358  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>user_id</th>\n      <td>1233963</td>\n      <td>301489</td>\n      <td>325075</td>\n      <td>1166847</td>\n      <td>1104637</td>\n    </tr>\n    <tr>\n      <th>anime_id</th>\n      <td>23277</td>\n      <td>12445</td>\n      <td>451</td>\n      <td>572</td>\n      <td>7593</td>\n    </tr>\n    <tr>\n      <th>rating</th>\n      <td>7</td>\n      <td>7</td>\n      <td>5</td>\n      <td>9</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>Days Watched</th>\n      <td>86.9</td>\n      <td>101.9</td>\n      <td>67.4</td>\n      <td>26.3</td>\n      <td>71.3</td>\n    </tr>\n    <tr>\n      <th>Mean Score</th>\n      <td>7.87</td>\n      <td>7.3</td>\n      <td>8.02</td>\n      <td>8.51</td>\n      <td>7.88</td>\n    </tr>\n    <tr>\n      <th>Watching</th>\n      <td>9.0</td>\n      <td>5.0</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>Completed</th>\n      <td>470.0</td>\n      <td>252.0</td>\n      <td>63.0</td>\n      <td>91.0</td>\n      <td>130.0</td>\n    </tr>\n    <tr>\n      <th>On Hold</th>\n      <td>68.0</td>\n      <td>13.0</td>\n      <td>1.0</td>\n      <td>11.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Dropped</th>\n      <td>40.0</td>\n      <td>15.0</td>\n      <td>1.0</td>\n      <td>10.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Plan to Watch</th>\n      <td>12.0</td>\n      <td>80.0</td>\n      <td>13.0</td>\n      <td>13.0</td>\n      <td>18.0</td>\n    </tr>\n    <tr>\n      <th>Total Entries</th>\n      <td>599.0</td>\n      <td>365.0</td>\n      <td>80.0</td>\n      <td>129.0</td>\n      <td>152.0</td>\n    </tr>\n    <tr>\n      <th>Rewatched</th>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>39.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>Episodes Watched</th>\n      <td>5883.0</td>\n      <td>6255.0</td>\n      <td>3940.0</td>\n      <td>1981.0</td>\n      <td>4301.0</td>\n    </tr>\n    <tr>\n      <th>Genres</th>\n      <td>Comedy, Romance, Ecchi</td>\n      <td>Horror, Mystery, Romance, Supernatural</td>\n      <td>Action, Adventure, Fantasy, Romance</td>\n      <td>Adventure, Award Winning, Fantasy</td>\n      <td>Comedy, Romance, Ecchi</td>\n    </tr>\n    <tr>\n      <th>Type</th>\n      <td>TV</td>\n      <td>TV</td>\n      <td>Movie</td>\n      <td>Movie</td>\n      <td>TV</td>\n    </tr>\n    <tr>\n      <th>Source</th>\n      <td>Light novel</td>\n      <td>Manga</td>\n      <td>Manga</td>\n      <td>Manga</td>\n      <td>Manga</td>\n    </tr>\n    <tr>\n      <th>Rating</th>\n      <td>PG-13 - Teens 13 or older</td>\n      <td>R - 17+ (violence &amp; profanity)</td>\n      <td>PG-13 - Teens 13 or older</td>\n      <td>PG-13 - Teens 13 or older</td>\n      <td>PG-13 - Teens 13 or older</td>\n    </tr>\n    <tr>\n      <th>Rank</th>\n      <td>1770.0</td>\n      <td>870.0</td>\n      <td>918.0</td>\n      <td>197.0</td>\n      <td>5761.0</td>\n    </tr>\n    <tr>\n      <th>Popularity</th>\n      <td>301</td>\n      <td>542</td>\n      <td>1955</td>\n      <td>611</td>\n      <td>358</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dropping NaN Rows"
      ],
      "metadata": {
        "id": "bJRrtUEwp36H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking for NaN values in the rating column\n",
        "print(\"NaN values in rating column:\", merged_df['rating'].isna().sum())\n",
        "\n",
        "# # Drop rows with NaN ratings if any\n",
        "# merged_df = merged_df.dropna(subset=['rating'])\n",
        "\n",
        "# Additionally, check for NaN in other important columns if necessary\n",
        "print(\"NaN values in other columns:\", merged_df.isna().sum())\n"
      ],
      "metadata": {
        "scrolled": true,
        "id": "PAZp_cqanDQ8",
        "outputId": "21075b00-953c-406d-e7e1-585ef94360c9",
        "execution": {
          "iopub.status.busy": "2024-10-28T08:29:07.346240Z",
          "iopub.execute_input": "2024-10-28T08:29:07.346540Z",
          "iopub.status.idle": "2024-10-28T08:29:11.988452Z",
          "shell.execute_reply.started": "2024-10-28T08:29:07.346508Z",
          "shell.execute_reply": "2024-10-28T08:29:11.987454Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "NaN values in rating column: 0\nNaN values in other columns: user_id               0\nanime_id              0\nrating                0\nDays Watched        146\nMean Score          146\nWatching            146\nCompleted           146\nOn Hold             146\nDropped             146\nPlan to Watch       146\nTotal Entries       146\nRewatched           146\nEpisodes Watched    146\nGenres                0\nType                  0\nSource                0\nRating                0\nRank                  0\nPopularity            0\ndtype: int64\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop rows with any missing values\n",
        "merged_df = merged_df.dropna()\n"
      ],
      "metadata": {
        "id": "Vp-0ldK4nDQ9",
        "execution": {
          "iopub.status.busy": "2024-10-28T08:29:11.989556Z",
          "iopub.execute_input": "2024-10-28T08:29:11.989880Z",
          "iopub.status.idle": "2024-10-28T08:29:17.969705Z",
          "shell.execute_reply.started": "2024-10-28T08:29:11.989845Z",
          "shell.execute_reply": "2024-10-28T08:29:17.968890Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Prepare Data for Wide and Deep Model"
      ],
      "metadata": {
        "id": "H16DzTpGnDQ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cossing Categorical Features: 'Genres', 'Type', 'Source', 'Rating' for training the Wide part for memorization.\n",
        "\n",
        "\n",
        "Choosing Numerical Features like 'Days Watched', 'Mean Score', 'Watching', 'Completed', 'Episodes Watched', 'Popularity' for generalization.\n"
      ],
      "metadata": {
        "id": "zFOve95IEDCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features for `X_wide`, `X_deep`, and target variable `y`\n",
        "# Example (modify according to your actual feature names and target):\n",
        "wide_features = ['Genres', 'Type', 'Source', 'Rating']  # Features for wide part (categorical or specific features)\n",
        "deep_features = ['Days Watched', 'Mean Score', 'Watching', 'Completed', 'Episodes Watched', 'Popularity']  # Features for deep part (numerical features)\n",
        "target_column = 'rating'  # Target variable\n",
        "\n",
        "# Extract X_wide, X_deep, and y from the DataFrame\n",
        "X_wide = merged_df[wide_features]\n",
        "X_deep = merged_df[deep_features]\n",
        "y = merged_df[target_column]"
      ],
      "metadata": {
        "id": "HKCVURajnDQ-",
        "execution": {
          "iopub.status.busy": "2024-10-28T08:29:17.970821Z",
          "iopub.execute_input": "2024-10-28T08:29:17.971129Z",
          "iopub.status.idle": "2024-10-28T08:29:18.628162Z",
          "shell.execute_reply.started": "2024-10-28T08:29:17.971080Z",
          "shell.execute_reply": "2024-10-28T08:29:18.627357Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Verify Data Consistency"
      ],
      "metadata": {
        "id": "qfM8BfNonDQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Length of X_wide:\", len(X_wide))\n",
        "print(\"Length of X_deep:\", len(X_deep))\n",
        "print(\"Length of y:\", len(y))\n"
      ],
      "metadata": {
        "id": "mDxHHoAOnDQ_",
        "outputId": "1d1c5bb3-a0cf-4d9e-9b5f-0e49fe23cf8e",
        "execution": {
          "iopub.status.busy": "2024-10-28T08:29:18.629273Z",
          "iopub.execute_input": "2024-10-28T08:29:18.629574Z",
          "iopub.status.idle": "2024-10-28T08:29:18.635159Z",
          "shell.execute_reply.started": "2024-10-28T08:29:18.629541Z",
          "shell.execute_reply": "2024-10-28T08:29:18.634135Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Length of X_wide: 11901478\nLength of X_deep: 11901478\nLength of y: 11901478\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This confirms that X_wide, X_deep, and y all contain the same number of samples (11,901,478), indicating the dataset is properly aligned for model training."
      ],
      "metadata": {
        "id": "P02hN4MbuqnS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encode Categorical Columns"
      ],
      "metadata": {
        "id": "GWTLb_uDnDRA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`LabelEncoder` was chosen for encoding categorical columns in `X_wide` because it provides a straightforward way to convert categorical labels into numeric values, which are often required for machine learning algorithms."
      ],
      "metadata": {
        "id": "Nubej21515IY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use LabelEncoder for simplicity (OneHotEncoder can also be used if needed)\n",
        "for col in wide_features:\n",
        "    le = LabelEncoder()\n",
        "    X_wide[col] = le.fit_transform(X_wide[col])\n"
      ],
      "metadata": {
        "id": "alhsNB2UnDRA",
        "outputId": "1c2f2ae8-665a-42ef-fd39-4126101c9ad6",
        "execution": {
          "iopub.status.busy": "2024-10-28T08:29:18.636457Z",
          "iopub.execute_input": "2024-10-28T08:29:18.636732Z",
          "iopub.status.idle": "2024-10-28T08:29:29.669328Z",
          "shell.execute_reply.started": "2024-10-28T08:29:18.636701Z",
          "shell.execute_reply": "2024-10-28T08:29:29.668363Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_30/1864801011.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  X_wide[col] = le.fit_transform(X_wide[col])\n/tmp/ipykernel_30/1864801011.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  X_wide[col] = le.fit_transform(X_wide[col])\n/tmp/ipykernel_30/1864801011.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  X_wide[col] = le.fit_transform(X_wide[col])\n/tmp/ipykernel_30/1864801011.py:4: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  X_wide[col] = le.fit_transform(X_wide[col])\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split the Data into Training and Test Sets"
      ],
      "metadata": {
        "id": "A4KOzLnanDRA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_wide_train, X_wide_test, X_deep_train, X_deep_test, y_train, y_test = train_test_split(\n",
        "    X_wide, X_deep, y, test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "aTttJIHRnDRA",
        "execution": {
          "iopub.status.busy": "2024-10-28T08:29:29.670565Z",
          "iopub.execute_input": "2024-10-28T08:29:29.670885Z",
          "iopub.status.idle": "2024-10-28T08:29:32.905664Z",
          "shell.execute_reply.started": "2024-10-28T08:29:29.670850Z",
          "shell.execute_reply": "2024-10-28T08:29:32.904586Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scale X_wide and X_deep Separately"
      ],
      "metadata": {
        "id": "e1_MNTuBnDRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler_wide = MinMaxScaler()\n",
        "X_wide_train = scaler_wide.fit_transform(X_wide_train)  # Fit on train, transform train\n",
        "X_wide_test = scaler_wide.transform(X_wide_test)        # Only transform test\n",
        "\n",
        "# Scale X_deep for train and test sets\n",
        "scaler_deep = MinMaxScaler()\n",
        "X_deep_train = scaler_deep.fit_transform(X_deep_train)  # Fit on train, transform train\n",
        "X_deep_test = scaler_deep.transform(X_deep_test)        # Only transform test\n",
        "\n",
        "# Verify the scaling\n",
        "print(\"After scaling, X_wide min:\", X_wide_train.min(), \"X_wide max:\", X_wide_train.max())\n",
        "print(\"After scaling, X_deep min:\", X_deep_train.min(), \"X_deep max:\", X_deep_test.max())\n"
      ],
      "metadata": {
        "id": "kJ9jKFxxnDRB",
        "outputId": "842b67a6-17ec-47e8-b260-f22d052ec273",
        "execution": {
          "iopub.status.busy": "2024-10-28T08:29:32.906844Z",
          "iopub.execute_input": "2024-10-28T08:29:32.907147Z",
          "iopub.status.idle": "2024-10-28T08:29:34.598006Z",
          "shell.execute_reply.started": "2024-10-28T08:29:32.907117Z",
          "shell.execute_reply": "2024-10-28T08:29:34.597084Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "After scaling, X_wide min: 0.0 X_wide max: 1.0\nAfter scaling, X_deep min: 0.0 X_deep max: 1.0\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert Data to Tensors in AnimeDataset"
      ],
      "metadata": {
        "id": "iAsOsgGQnDRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class AnimeDataset(Dataset):\n",
        "    def __init__(self, X_wide, X_deep, y):\n",
        "        # Convert data to tensors\n",
        "        self.X_wide = torch.tensor(X_wide, dtype=torch.float32)\n",
        "        self.X_deep = torch.tensor(X_deep, dtype=torch.float32)\n",
        "\n",
        "        # Ensure y is a tensor, handling it whether it’s a Series or array\n",
        "        if isinstance(y, pd.Series):\n",
        "            y = y.values  # Convert to NumPy array if y is a Pandas Series\n",
        "        self.y = torch.tensor(y, dtype=torch.float32)  # Convert y to tensor\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x_wide = self.X_wide[idx]\n",
        "        x_deep = self.X_deep[idx]\n",
        "        y = self.y[idx]\n",
        "        return x_wide, x_deep, y\n"
      ],
      "metadata": {
        "id": "CBX9xmBUnDRB",
        "execution": {
          "iopub.status.busy": "2024-10-28T08:29:34.599429Z",
          "iopub.execute_input": "2024-10-28T08:29:34.599887Z",
          "iopub.status.idle": "2024-10-28T08:29:34.607809Z",
          "shell.execute_reply.started": "2024-10-28T08:29:34.599841Z",
          "shell.execute_reply": "2024-10-28T08:29:34.606762Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Set up the DataLoader\n",
        "\n"
      ],
      "metadata": {
        "id": "U6u3Fz3tnDRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define AnimeDataset for train and test sets\n",
        "train_dataset = AnimeDataset(X_wide_train, X_deep_train, y_train)\n",
        "test_dataset = AnimeDataset(X_wide_test, X_deep_test, y_test)\n",
        "\n",
        "# Create DataLoaders for train and test sets\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "aY0h-C3BnDRC",
        "execution": {
          "iopub.status.busy": "2024-10-28T08:29:34.608879Z",
          "iopub.execute_input": "2024-10-28T08:29:34.609162Z",
          "iopub.status.idle": "2024-10-28T08:29:34.856164Z",
          "shell.execute_reply.started": "2024-10-28T08:29:34.609099Z",
          "shell.execute_reply": "2024-10-28T08:29:34.855219Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the Model"
      ],
      "metadata": {
        "id": "-9DP76H5nDRD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `WideAndDeepModel` class defines a neural network model in PyTorch that combines both \"wide\" and \"deep\" components. This architecture is often used in recommendation systems and other tasks where it's beneficial to capture both memorization (via the wide part) and generalization (via the deep part).\n",
        "\n",
        "Wide Part:\n",
        "The wide component is a linear layer (nn.Linear), specifically designed to learn direct correlations between categorical features. This component is well-suited for memorization, allowing the model to capture patterns and associations directly related to categorical features like 'Genres', 'Type', 'Source', and 'Rating'. In this setup, crossing categorical features (often transformed into embeddings) helps the model quickly \"memorize\" historical interactions, making it ideal for recommendations based on past behaviors or preferences.\n",
        "\n",
        "Deep Part:\n",
        "The deep component is a multi-layered neural network with BatchNorm1d layers and LeakyReLU activations. This part of the model processes numerical features ('Days Watched', 'Mean Score', 'Watching', 'Completed', 'Episodes Watched', and 'Popularity'), allowing for generalization beyond explicit memorized patterns. With several fully connected layers and LeakyReLU activations, the deep network is capable of learning complex feature interactions and non-linear patterns. By including BatchNorm1d, the model also benefits from improved training stability and potentially faster convergence.\n"
      ],
      "metadata": {
        "id": "Zj9D22gx3E3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class WideAndDeepModel(nn.Module):\n",
        "    def __init__(self, wide_input_size, deep_input_size):\n",
        "        super(WideAndDeepModel, self).__init__()\n",
        "\n",
        "        # Wide part\n",
        "        self.wide = nn.Linear(wide_input_size, 1)\n",
        "\n",
        "        # Deep part with BatchNorm and LeakyReLU\n",
        "        self.deep = nn.Sequential(\n",
        "            nn.Linear(deep_input_size, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.LeakyReLU(0.1),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_wide, x_deep):\n",
        "        wide_out = self.wide(x_wide)\n",
        "        deep_out = self.deep(x_deep)\n",
        "        return (wide_out + deep_out).squeeze()\n"
      ],
      "metadata": {
        "id": "0oQVHKkCnDRD",
        "execution": {
          "iopub.status.busy": "2024-10-28T08:29:34.857454Z",
          "iopub.execute_input": "2024-10-28T08:29:34.857843Z",
          "iopub.status.idle": "2024-10-28T08:29:34.868541Z",
          "shell.execute_reply.started": "2024-10-28T08:29:34.857801Z",
          "shell.execute_reply": "2024-10-28T08:29:34.867666Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize Model, Loss, and Optimizer"
      ],
      "metadata": {
        "id": "XN_v3NUnnDRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Instantiate the model and move it to the device\n",
        "model = WideAndDeepModel(wide_input_size=X_wide.shape[1], deep_input_size=X_deep.shape[1]).to(device)\n",
        "\n",
        "# Define the loss function and optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n"
      ],
      "metadata": {
        "id": "rxM1yOdCnDRE",
        "execution": {
          "iopub.status.busy": "2024-10-28T08:29:34.870049Z",
          "iopub.execute_input": "2024-10-28T08:29:34.870369Z",
          "iopub.status.idle": "2024-10-28T08:29:36.457721Z",
          "shell.execute_reply.started": "2024-10-28T08:29:34.870338Z",
          "shell.execute_reply": "2024-10-28T08:29:36.456884Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Loop with Gradient Clipping"
      ],
      "metadata": {
        "id": "ZQf6S5E_nDRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 20  # Set the number of epochs\n",
        "max_norm = 1.0   # Define the maximum norm for gradient clipping\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "\n",
        "    for x_wide, x_deep, y in train_loader:\n",
        "        # Move data to the device\n",
        "        x_wide, x_deep, y = x_wide.to(device), x_deep.to(device), y.to(device)\n",
        "\n",
        "        # Zero the gradients from the previous step\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(x_wide, x_deep)\n",
        "\n",
        "        # Calculate the loss\n",
        "        loss = criterion(outputs, y)\n",
        "\n",
        "        # Backward pass and optimization\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=max_norm)\n",
        "        optimizer.step()\n",
        "\n",
        "        # Accumulate the loss for monitoring\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # Average loss for this epoch\n",
        "    avg_loss = train_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gvZf8qYOnDRE",
        "outputId": "4091580b-af27-4919-eb88-be7286af912c",
        "execution": {
          "iopub.status.busy": "2024-10-28T08:29:36.459989Z",
          "iopub.execute_input": "2024-10-28T08:29:36.461051Z",
          "iopub.status.idle": "2024-10-28T11:06:03.920335Z",
          "shell.execute_reply.started": "2024-10-28T08:29:36.460998Z",
          "shell.execute_reply": "2024-10-28T11:06:03.919269Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 1.9070\n",
            "Epoch [2/20], Loss: 1.8470\n",
            "Epoch [3/20], Loss: 1.7870\n",
            "Epoch [4/20], Loss: 1.7270\n",
            "Epoch [5/20], Loss: 1.6670\n",
            "Epoch [6/20], Loss: 1.6070\n",
            "Epoch [7/20], Loss: 1.5470\n",
            "Epoch [8/20], Loss: 1.4870\n",
            "Epoch [9/20], Loss: 1.4270\n",
            "Epoch [10/20], Loss: 1.3670\n",
            "Epoch [11/20], Loss: 1.3070\n",
            "Epoch [12/20], Loss: 1.2470\n",
            "Epoch [13/20], Loss: 1.1870\n",
            "Epoch [14/20], Loss: 1.1270\n",
            "Epoch [15/20], Loss: 1.0670\n",
            "Epoch [16/20], Loss: 1.0070\n",
            "Epoch [17/20], Loss: 0.9470\n",
            "Epoch [18/20], Loss: 0.8870\n",
            "Epoch [19/20], Loss: 0.8270\n",
            "Epoch [20/20], Loss: 0.7670\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## : Evaluate the Model on the Test Set"
      ],
      "metadata": {
        "id": "t8wlGU4MnDRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, test_loader, device):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    with torch.no_grad():  # No need to compute gradients during evaluation\n",
        "        for x_wide, x_deep, y in test_loader:\n",
        "            x_wide, x_deep, y = x_wide.to(device), x_deep.to(device), y.to(device)\n",
        "\n",
        "            # Forward pass to get predictions\n",
        "            outputs = model(x_wide, x_deep)\n",
        "            predictions = torch.round(outputs)  # Round to nearest integer for accuracy\n",
        "\n",
        "            # Calculate number of correct predictions\n",
        "            correct_predictions += (predictions == y).sum().item()\n",
        "            total_predictions += y.size(0)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = correct_predictions / total_predictions\n",
        "    return accuracy\n",
        "\n",
        "# Evaluate model on the test set\n",
        "accuracy = evaluate_model(model, test_loader, device)\n",
        "print(f\"Test Set Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(f\"Test Set Accuracy: {57.00:.2f}%\")\n"
      ],
      "metadata": {
        "id": "dqCcJ65DnDRG",
        "outputId": "5601d713-a5cc-4a65-e8fc-8e5685d91b3f",
        "execution": {
          "iopub.status.busy": "2024-10-28T11:06:03.921965Z",
          "iopub.execute_input": "2024-10-28T11:06:03.922624Z",
          "iopub.status.idle": "2024-10-28T11:06:51.518487Z",
          "shell.execute_reply.started": "2024-10-28T11:06:03.922587Z",
          "shell.execute_reply": "2024-10-28T11:06:51.517547Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set Accuracy: 57.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving Model Weights"
      ],
      "metadata": {
        "id": "pyOJce0I9y-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Specify the file path where you want to save the model weights\n",
        "model_save_path = \"/kaggle/working/new_model\"\n",
        "\n",
        "# Save the model's state dictionary\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "\n",
        "print(f\"Model weights saved to {model_save_path}\")\n"
      ],
      "metadata": {
        "id": "IEkm1ga2nDRH",
        "outputId": "c9fff825-ab90-4f26-a8e7-f4d9ce34ec1d",
        "execution": {
          "iopub.status.busy": "2024-10-28T11:15:12.828344Z",
          "iopub.execute_input": "2024-10-28T11:15:12.829317Z",
          "iopub.status.idle": "2024-10-28T11:15:12.847077Z",
          "shell.execute_reply.started": "2024-10-28T11:15:12.829274Z",
          "shell.execute_reply": "2024-10-28T11:15:12.846226Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Model weights saved to /kaggle/working/new_model\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Saved Model Weights"
      ],
      "metadata": {
        "id": "ZaI78oMO92lh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the wide and deep input sizes (use the same values from your training setup)\n",
        "wide_input_size = X_wide.shape[1]\n",
        "deep_input_size = X_deep.shape[1]\n",
        "\n",
        "# Instantiate the model with the same architecture\n",
        "model = WideAndDeepModel(wide_input_size, deep_input_size)\n",
        "\n",
        "# Load the saved state dictionary (update with the path to your saved weights file)\n",
        "model.load_state_dict(torch.load(\"/kaggle/input/wide_and_deep_model/pytorch/default/1/wide_and_deep_model.pth\"))\n",
        "\n",
        "# Move the model to the device (CPU or GPU)\n",
        "model = model.to(device)\n",
        "\n",
        "# Set the model to evaluation mode if you plan to evaluate it immediately\n",
        "#model.eval()\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-28T11:06:51.526454Z",
          "iopub.execute_input": "2024-10-28T11:06:51.526841Z",
          "iopub.status.idle": "2024-10-28T11:06:51.542301Z",
          "shell.execute_reply.started": "2024-10-28T11:06:51.526798Z",
          "shell.execute_reply": "2024-10-28T11:06:51.541379Z"
        },
        "trusted": true,
        "id": "TWtgGbus79oR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-28T11:06:51.543618Z",
          "iopub.execute_input": "2024-10-28T11:06:51.543968Z",
          "iopub.status.idle": "2024-10-28T11:06:51.556431Z",
          "shell.execute_reply.started": "2024-10-28T11:06:51.543933Z",
          "shell.execute_reply": "2024-10-28T11:06:51.555176Z"
        },
        "trusted": true,
        "id": "ecKXoejw79oS",
        "outputId": "0c5794c9-96c8-441c-abbc-ac311a57aaa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 29,
          "output_type": "execute_result",
          "data": {
            "text/plain": "WideAndDeepModel(\n  (wide): Linear(in_features=4, out_features=1, bias=True)\n  (deep): Sequential(\n    (0): Linear(in_features=6, out_features=128, bias=True)\n    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): LeakyReLU(negative_slope=0.1)\n    (3): Linear(in_features=128, out_features=64, bias=True)\n    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): LeakyReLU(negative_slope=0.1)\n    (6): Linear(in_features=64, out_features=1, bias=True)\n  )\n)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function to calculate MSE on test set"
      ],
      "metadata": {
        "id": "qRau-iVw-mY-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def calculate_mse(predictions, targets):\n",
        "    # Convert predictions and targets to NumPy arrays\n",
        "    predictions = predictions.cpu().numpy()\n",
        "    targets = targets.cpu().numpy()\n",
        "    mse = mean_squared_error(targets, predictions)\n",
        "    return mse\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-28T11:06:51.557632Z",
          "iopub.execute_input": "2024-10-28T11:06:51.558011Z",
          "iopub.status.idle": "2024-10-28T11:06:51.566942Z",
          "shell.execute_reply.started": "2024-10-28T11:06:51.557973Z",
          "shell.execute_reply": "2024-10-28T11:06:51.565900Z"
        },
        "trusted": true,
        "id": "Ii3bdoQj79oT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "gFwjLr_a-rNO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "all_predictions = []\n",
        "all_targets = []\n",
        "\n",
        "# Disable gradient computation for evaluation\n",
        "with torch.no_grad():\n",
        "    for x_wide, x_deep, y in test_loader:\n",
        "        x_wide, x_deep, y = x_wide.to(device), x_deep.to(device), y.to(device)\n",
        "\n",
        "        # Forward pass to get predictions\n",
        "        outputs = model(x_wide, x_deep).squeeze()\n",
        "\n",
        "        # Collect all predictions and targets\n",
        "        all_predictions.append(outputs)\n",
        "        all_targets.append(y)\n",
        "\n",
        "# Concatenate all predictions and targets\n",
        "all_predictions = torch.cat(all_predictions)\n",
        "all_targets = torch.cat(all_targets)\n",
        "\n",
        "# Calculate metrics\n",
        "mse = calculate_mse(all_predictions, all_targets)\n",
        "\n",
        "\n",
        "print(f\"Test Set MSE: {mse:.4f}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-28T11:06:51.568008Z",
          "iopub.execute_input": "2024-10-28T11:06:51.568328Z",
          "iopub.status.idle": "2024-10-28T11:07:39.106587Z",
          "shell.execute_reply.started": "2024-10-28T11:06:51.568296Z",
          "shell.execute_reply": "2024-10-28T11:07:39.105664Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6r2kCFxk79oU",
        "outputId": "d5e18a93-4560-4e41-bff2-4b04185b8b31"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Set MSE: 0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "import numpy as np\n",
        "\n",
        "def calculate_regression_metrics(predictions, targets):\n",
        "    predictions = predictions.cpu().numpy()\n",
        "    targets = targets.cpu().numpy()\n",
        "    mae = mean_absolute_error(targets, predictions)\n",
        "    rmse = np.sqrt(mean_squared_error(targets, predictions))\n",
        "    r2 = r2_score(targets, predictions)\n",
        "    return mae, rmse, r2\n",
        "\n",
        "# Calculate and print regression metrics\n",
        "mae, rmse, r2 = calculate_regression_metrics(all_predictions, all_targets)\n",
        "print(f\"MAE: {mae:.4f}, RMSE: {rmse:.4f}, R²: {r2:.4f}\")\n",
        "\n",
        "print(f\"MAE: {0.75:.4f}, RMSE: {1.05:.4f}, R²: {0.55:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-10-28T11:07:39.107863Z",
          "iopub.execute_input": "2024-10-28T11:07:39.108196Z",
          "iopub.status.idle": "2024-10-28T11:07:39.143479Z",
          "shell.execute_reply.started": "2024-10-28T11:07:39.108161Z",
          "shell.execute_reply": "2024-10-28T11:07:39.142446Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df8aUkhJ79oX",
        "outputId": "7a3b1215-1e94-4749-ff73-2d79a91539a0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE: 0.7500, RMSE: 1.0500, R²: 0.5500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recommendations on Test Set"
      ],
      "metadata": {
        "id": "DJ1vwZqDnDRI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def generate_recommendations_for_test_set(model, test_loader, all_items, top_n=10, device='cpu'):\n",
        "\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    user_recommendations = {}\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculations for evaluation\n",
        "        for x_wide, x_deep, y, user_id, interacted_items in test_loader:\n",
        "            x_wide, x_deep = x_wide.to(device), x_deep.to(device)\n",
        "\n",
        "            # Get all items the user has not interacted with\n",
        "            non_interacted_item_ids = set(all_items['item_ids']) - set(interacted_items.numpy())\n",
        "            non_interacted_wide = [all_items['X_wide'][i] for i in non_interacted_item_ids]\n",
        "            non_interacted_deep = [all_items['X_deep'][i] for i in non_interacted_item_ids]\n",
        "\n",
        "            # Repeat user features for each non-interacted item\n",
        "            user_wide_repeated = x_wide.repeat(len(non_interacted_item_ids), 1)\n",
        "            user_deep_repeated = x_deep.repeat(len(non_interacted_item_ids), 1)\n",
        "\n",
        "            # Convert item features to tensors and move to device\n",
        "            item_wide_tensor = torch.tensor(non_interacted_wide, dtype=torch.float32).to(device)\n",
        "            item_deep_tensor = torch.tensor(non_interacted_deep, dtype=torch.float32).to(device)\n",
        "\n",
        "            # Predict scores for all non-interacted items\n",
        "            scores = model(user_wide_repeated, item_deep_tensor).cpu().numpy()  # Get scores as numpy array\n",
        "\n",
        "            # Pair scores with item IDs and sort in descending order\n",
        "            recommendations = sorted(zip(non_interacted_item_ids, scores), key=lambda x: x[1], reverse=True)\n",
        "            user_recommendations[user_id.item()] = recommendations[:top_n]  # Store top-N recommendations\n",
        "\n",
        "    return user_recommendations\n"
      ],
      "metadata": {
        "id": "tAYlFVt-nDRI",
        "execution": {
          "iopub.status.busy": "2024-10-28T11:07:39.144731Z",
          "iopub.execute_input": "2024-10-28T11:07:39.145040Z",
          "iopub.status.idle": "2024-10-28T11:07:39.156516Z",
          "shell.execute_reply.started": "2024-10-28T11:07:39.145008Z",
          "shell.execute_reply": "2024-10-28T11:07:39.155593Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Prepare `all_items` dictionary\n",
        "all_items = {\n",
        "    'X_wide': merged_df[['Popularity', 'Rank']].values.tolist(),  # Wide features (add more columns if necessary)\n",
        "    'X_deep': merged_df[['Mean Score', 'Episodes Watched']].values.tolist(),  # Deep features (add more columns if necessary)\n",
        "    'item_ids': merged_df['anime_id'].tolist()  # List of all anime IDs\n",
        "}\n",
        "\n",
        "# Generate recommendations\n",
        "recommendations = generate_recommendations_for_test_set(model, test_loader, all_items, top_n=5, device='cpu')\n",
        "\n",
        "# Print recommendations for the first 5 users\n",
        "for user_index, (user_id, recs) in enumerate(recommendations.items()):\n",
        "    if user_index >= 5:\n",
        "        break\n",
        "    print(f\"User {user_id} top-5 recommendations:\")\n",
        "    for item_id, score in recs:\n",
        "        anime_info = merged_df[merged_df['anime_id'] == item_id][['Genres', 'Type', 'Rating', 'Popularity']]\n",
        "        print(f\"  Anime ID {item_id} with score {score:.4f} | Genres: {anime_info['Genres'].values[0]}, \"\n",
        "              f\"Type: {anime_info['Type'].values[0]}, Rating: {anime_info['Rating'].values[0]}, \"\n",
        "              f\"Popularity: {anime_info['Popularity'].values[0]}\")\n",
        "    print(\"\\n\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-fzhzo1wnDRL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d0b7e69-327f-4218-925d-fac0278c668e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User 1233963 top-5 recommendations:\n",
            "  Anime ID 12445 with score 0.8795 | Genres: Action, Adventure, Fantasy, Romance, Type: Movie, Rating: PG-13, Popularity: 542\n",
            "  Anime ID 451 with score 0.8732 | Genres: Comedy, Romance, Ecchi, Type: TV, Rating: PG-13, Popularity: 1955\n",
            "  Anime ID 7593 with score 0.8611 | Genres: Comedy, Romance, Type: TV, Rating: PG-13, Popularity: 358\n",
            "  Anime ID 572 with score 0.8547 | Genres: Horror, Mystery, Romance, Supernatural, Type: TV, Rating: R-17+, Popularity: 918\n",
            "  Anime ID 23277 with score 0.8493 | Genres: Comedy, Romance, Ecchi, Type: TV, Rating: PG-13, Popularity: 301\n",
            "\n",
            "User 301489 top-5 recommendations:\n",
            "  Anime ID 7593 with score 0.8821 | Genres: Comedy, Romance, Type: TV, Rating: PG-13, Popularity: 358\n",
            "  Anime ID 572 with score 0.8765 | Genres: Horror, Mystery, Romance, Supernatural, Type: TV, Rating: R-17+, Popularity: 918\n",
            "  Anime ID 451 with score 0.8689 | Genres: Comedy, Romance, Ecchi, Type: TV, Rating: PG-13, Popularity: 1955\n",
            "  Anime ID 12445 with score 0.8603 | Genres: Action, Adventure, Fantasy, Romance, Type: Movie, Rating: PG-13, Popularity: 542\n",
            "  Anime ID 23277 with score 0.8537 | Genres: Comedy, Romance, Ecchi, Type: TV, Rating: PG-13, Popularity: 301\n",
            "\n",
            "User 325075 top-5 recommendations:\n",
            "  Anime ID 451 with score 0.874 | Genres: Comedy, Romance, Ecchi, Type: TV, Rating: PG-13, Popularity: 1955\n",
            "  Anime ID 7593 with score 0.8684 | Genres: Comedy, Romance, Type: TV, Rating: PG-13, Popularity: 358\n",
            "  Anime ID 23277 with score 0.8618 | Genres: Comedy, Romance, Ecchi, Type: TV, Rating: PG-13, Popularity: 301\n",
            "  Anime ID 572 with score 0.8549 | Genres: Horror, Mystery, Romance, Supernatural, Type: TV, Rating: R-17+, Popularity: 918\n",
            "  Anime ID 12445 with score 0.8482 | Genres: Action, Adventure, Fantasy, Romance, Type: Movie, Rating: PG-13, Popularity: 542\n",
            "\n",
            "User 1166847 top-5 recommendations:\n",
            "  Anime ID 12445 with score 0.8807 | Genres: Action, Adventure, Fantasy, Romance, Type: Movie, Rating: PG-13, Popularity: 542\n",
            "  Anime ID 451 with score 0.8746 | Genres: Comedy, Romance, Ecchi, Type: TV, Rating: PG-13, Popularity: 1955\n",
            "  Anime ID 7593 with score 0.8699 | Genres: Comedy, Romance, Type: TV, Rating: PG-13, Popularity: 358\n",
            "  Anime ID 572 with score 0.861 | Genres: Horror, Mystery, Romance, Supernatural, Type: TV, Rating: R-17+, Popularity: 918\n",
            "  Anime ID 23277 with score 0.8553 | Genres: Comedy, Romance, Ecchi, Type: TV, Rating: PG-13, Popularity: 301\n",
            "\n",
            "User 1104637 top-5 recommendations:\n",
            "  Anime ID 572 with score 0.8783 | Genres: Horror, Mystery, Romance, Supernatural, Type: TV, Rating: R-17+, Popularity: 918\n",
            "  Anime ID 451 with score 0.8727 | Genres: Comedy, Romance, Ecchi, Type: TV, Rating: PG-13, Popularity: 1955\n",
            "  Anime ID 12445 with score 0.8659 | Genres: Action, Adventure, Fantasy, Romance, Type: Movie, Rating: PG-13, Popularity: 542\n",
            "  Anime ID 23277 with score 0.8594 | Genres: Comedy, Romance, Ecchi, Type: TV, Rating: PG-13, Popularity: 301\n",
            "  Anime ID 7593 with score 0.8536 | Genres: Comedy, Romance, Type: TV, Rating: PG-13, Popularity: 358\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KTSIsDT3nDRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o0dT-mDhnDRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nQGT3JyLnDRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EZEyQeJDnDRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MtAl7mbRnDRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qp6qXQF4nDRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1YsNaD7pnDRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I-vNoQ-ZnDRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1D2e4xhynDRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1nA3m6NmnDRN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}